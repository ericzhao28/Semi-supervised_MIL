{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image, ImageSequence\n",
    "import glob\n",
    "\n",
    "\n",
    "T_pred = 16\n",
    "T_in = 16\n",
    "vid_l = T_in + T_pred\n",
    "IMG_H = 125\n",
    "IMG_W = 125\n",
    "IMG_CH = 3\n",
    "DATA_PATH = \"/home/ubuntu/data/sim_push/\"\n",
    "\n",
    "\n",
    "def gif_to_np(path):\n",
    "  def __frame_to_np(frame):\n",
    "    return np.array(frame.copy().convert(\"RGB\").getdata(),\n",
    "                    dtype=np.uint8).reshape(frame.size[1],\n",
    "                                            frame.size[0], 3)\n",
    "\n",
    "  im = Image.open(path)\n",
    "  data = np.array(list(map(__frame_to_np, ImageSequence.Iterator(im))))\n",
    "  return data\n",
    "\n",
    "\n",
    "def load_path(paths_queue):\n",
    "  for p in glob.glob(DATA_PATH + \"*/*.gif\"):\n",
    "    paths_queue.put(p)\n",
    "  return\n",
    "\n",
    "\n",
    "def load_data(paths_queue, data_queue):\n",
    "    time.sleep(1)\n",
    "    while not paths_queue.empty():\n",
    "      data = gif_to_np(paths_queue.get())\n",
    "      assert(data.shape == (100, IMG_H, IMG_W, IMG_CH))\n",
    "\n",
    "      for i in range(0, data.shape[0] - (data.shape[0] % vid_l), vid_l):\n",
    "          assert(data[i:i + vid_l].shape == (vid_l, IMG_H, IMG_W, IMG_CH))\n",
    "          data_queue.put((data[i:i + T_in], data[i + T_in:i + vid_l]))\n",
    "      # Get left overs if sufficient size:\n",
    "      leftover_size = data.shape[0] % vid_l\n",
    "      if leftover_size >= T_in + 3:\n",
    "          leftover = data[:-leftover_size]\n",
    "          leftover_X = leftover[:T_in]\n",
    "          leftover_Y = np.zeros((T_pred, IMG_H, IMG_W, IMG_CH))\n",
    "          leftover_Y[:leftover_size - T_in] = leftover[T_in:]\n",
    "          data_queue.put((leftover_X, leftover_Y))\n",
    "    return\n",
    "  \n",
    "  \n",
    "def stream_data():\n",
    "  paths_queue = mp.Queue(maxsize=200)\n",
    "  path_process = mp.Process(target=load_path, args=(paths_queue,))\n",
    "  path_process.start()\n",
    "\n",
    "  data_queue = mp.Queue(maxsize=50)\n",
    "  processes = [mp.Process(target=load_data, args=(paths_queue, data_queue))\n",
    "               for i in range(mp.cpu_count())]\n",
    "  for proc in processes:\n",
    "      proc.start()\n",
    "\n",
    "  while True:\n",
    "    if (data_queue.empty()):\n",
    "      if any(p.is_alive() for p in processes + [path_process]):\n",
    "        time.sleep(0.5)\n",
    "        continue\n",
    "      else:\n",
    "        break\n",
    "    yield data_queue.get()\n",
    "\n",
    "  for proc in processes + [path_process]:\n",
    "      proc.join()\n",
    "\n",
    "      \n",
    "def batch_stream(batch_s):\n",
    "    data_stream = stream_data()\n",
    "    while True:\n",
    "        batch_X = np.zeros((batch_s, T_in, IMG_H, IMG_W, IMG_CH))\n",
    "        batch_Y = np.zeros((batch_s, T_pred, IMG_H, IMG_W, IMG_CH))\n",
    "        for i in range(batch_s):\n",
    "            try:\n",
    "                batch_X[i], batch_Y[i] = next(data_stream)\n",
    "            except StopIteration:\n",
    "                return\n",
    "        yield batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "chunk_size = 64\n",
    "dtype = np.uint8\n",
    "chunk_shape = (chunk_size, 16, 125, 125, 3)\n",
    "maxshape = (None,) + chunk_shape[1:]\n",
    "\n",
    "gen = stream_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "for obj in gc.get_objects():   # Browse through ALL objects\n",
    "  try:\n",
    "    if isinstance(obj, h5py.File):   # Just HDF5 files\n",
    "        try:\n",
    "            obj.close()\n",
    "        except:\n",
    "            pass # Was already closed\n",
    "  except:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing to 64\n",
      "Resizing to 128\n",
      "Resizing to 192\n",
      "Resizing to 256\n",
      "Resizing to 320\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/home/ubuntu/bigstorage/dataset.h5', 'w') as f:\n",
    "    X_dset = f.create_dataset('X', shape=chunk_shape, maxshape=maxshape,\n",
    "                              chunks=chunk_shape, dtype=dtype)\n",
    "    Y_dset = f.create_dataset('Y', shape=chunk_shape, maxshape=maxshape,\n",
    "                              chunks=chunk_shape, dtype=dtype)\n",
    "\n",
    "    row_count = 0\n",
    "    for x, y in gen:\n",
    "        if row_count % chunk_size == 0:\n",
    "          print(\"Resizing to\", row_count + chunk_size)\n",
    "          X_dset.resize(row_count + chunk_size, axis=0)\n",
    "          Y_dset.resize(row_count + chunk_size, axis=0)\n",
    "        X_dset[row_count:] = x\n",
    "        Y_dset[row_count:] = y\n",
    "        row_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "BATCH = 64\n",
    "\n",
    "with h5py.File('/home/ubuntu/bigstorage/dataset.h5', 'r') as f:\n",
    "    print(f['X'].shape)\n",
    "    print(f['Y'].shape)\n",
    "    \n",
    "\n",
    "model.fit_generator(train, validation_data=test,\n",
    "                    validation_steps=10, steps_per_epoch=55424,\n",
    "                    epochs=10, shuffle=True, workers = mp.cpu_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
