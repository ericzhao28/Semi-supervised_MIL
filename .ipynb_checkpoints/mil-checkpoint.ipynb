{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This file defines Meta Imitation Learning (MIL). \"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "from natsort import natsorted\n",
    "\n",
    "class MIL(object):\n",
    "    def init_network(self, graph, input_tensors=None, restore_iter=0, prefix='Training_'):\n",
    "        \"\"\" Helper method to initialize the tf networks used \"\"\"\n",
    "        with graph.as_default():\n",
    "            with Timer('building TF network'):\n",
    "                result = self.construct_model(input_tensors=input_tensors, prefix=prefix, dim_input=self._dO, dim_output=self._dU,\n",
    "                                          network_config=self.network_params)\n",
    "            outputas, outputbs, lossesa, lossesb, flat_img_inputb, gradients = result\n",
    "\n",
    "            trainable_vars = tf.trainable_variables()\n",
    "            total_loss1 = tf.reduce_sum(lossesa) / tf.to_float(self.meta_batch_size)\n",
    "            total_losses2 = [tf.reduce_sum(lossesb[j]) / tf.to_float(self.meta_batch_size) for j in range(self.num_updates)]\n",
    "\n",
    "            self.total_loss1 = total_loss1\n",
    "            self.total_losses2 = total_losses2\n",
    "            self.train_op = tf.train.AdamOptimizer(self.meta_lr).minimize(self.total_losses2[self.num_updates - 1])\n",
    "\n",
    "\n",
    "    def construct_image_input(self, nn_input, state_idx, img_idx, network_config=None):\n",
    "        \"\"\" Preprocess images. \"\"\"\n",
    "        state_input = nn_input[:, 0:state_idx[-1]+1]\n",
    "        flat_image_input = nn_input[:, state_idx[-1]+1:img_idx[-1]+1]\n",
    "\n",
    "        # image goes through 3 convnet layers\n",
    "        num_filters = network_config['num_filters']\n",
    "\n",
    "        im_height = network_config['image_height']\n",
    "        im_width = network_config['image_width']\n",
    "        num_channels = network_config['image_channels']\n",
    "        image_input = tf.reshape(flat_image_input, [-1, num_channels, im_width, im_height])\n",
    "        image_input = tf.transpose(image_input, perm=[0,3,2,1])\n",
    "        return image_input, flat_image_input, state_input\n",
    "\n",
    "    def construct_weights(self, dim_input=27, dim_output=7, network_config=None):\n",
    "        \"\"\" Construct weights for the network. \"\"\"\n",
    "        weights = {}\n",
    "        num_filters = network_config['num_filters']\n",
    "        strides = network_config.get('strides', [[1, 2, 2, 1], [1, 2, 2, 1], [1, 2, 2, 1]])\n",
    "        filter_sizes = network_config.get('filter_size', [3]*len(strides)) # used to be 2\n",
    "        if type(filter_sizes) is not list:\n",
    "            filter_sizes = len(strides)*[filter_sizes]\n",
    "        im_height = network_config['image_height']\n",
    "        im_width = network_config['image_width']\n",
    "        num_channels = network_config['image_channels']\n",
    "        is_dilated = network_config.get('is_dilated', False)\n",
    "        use_fp = FLAGS.fp\n",
    "        pretrain = FLAGS.pretrain_weight_path != 'N/A'\n",
    "        train_pretrain_conv1 = FLAGS.train_pretrain_conv1\n",
    "        initialization = network_config.get('initialization', 'random')\n",
    "        pretrain_weight_path = FLAGS.pretrain_weight_path\n",
    "        n_conv_layers = len(num_filters)\n",
    "        downsample_factor = 1\n",
    "        for stride in strides:\n",
    "            downsample_factor *= stride[1]\n",
    "        if use_fp:\n",
    "            self.conv_out_size = int(num_filters[-1]*2)\n",
    "        else:\n",
    "            self.conv_out_size = int(np.ceil(im_width/(downsample_factor)))*int(np.ceil(im_height/(downsample_factor)))*num_filters[-1]\n",
    "\n",
    "        # conv weights\n",
    "        fan_in = num_channels\n",
    "        if FLAGS.conv_bt:\n",
    "            fan_in += num_channels\n",
    "        if FLAGS.conv_bt:\n",
    "            weights['img_context'] = safe_get('img_context', initializer=tf.zeros([im_height, im_width, num_channels], dtype=tf.float32))\n",
    "            weights['img_context'] = tf.clip_by_value(weights['img_context'], 0., 1.)\n",
    "        for i in xrange(n_conv_layers):\n",
    "            if not pretrain or i != 0:\n",
    "                if self.norm_type == 'selu':\n",
    "                    weights['wc%d' % (i+1)] = init_conv_weights_snn([filter_sizes[i], filter_sizes[i], fan_in, num_filters[i]], name='wc%d' % (i+1)) # 5x5 conv, 1 input, 32 outputs\n",
    "                elif initialization == 'xavier':\n",
    "                    weights['wc%d' % (i+1)] = init_conv_weights_xavier([filter_sizes[i], filter_sizes[i], fan_in, num_filters[i]], name='wc%d' % (i+1)) # 5x5 conv, 1 input, 32 outputs\n",
    "                elif initialization == 'random':\n",
    "                    weights['wc%d' % (i+1)] = init_weights([filter_sizes[i], filter_sizes[i], fan_in, num_filters[i]], name='wc%d' % (i+1)) # 5x5 conv, 1 input, 32 outputs\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "                weights['bc%d' % (i+1)] = init_bias([num_filters[i]], name='bc%d' % (i+1))\n",
    "                fan_in = num_filters[i]\n",
    "            else:\n",
    "                import h5py\n",
    "\n",
    "                assert num_filters[i] == 64\n",
    "                vgg_filter_size = 3\n",
    "                weights['wc%d' % (i+1)] = safe_get('wc%d' % (i+1), [vgg_filter_size, vgg_filter_size, fan_in, num_filters[i]], dtype=tf.float32, trainable=train_pretrain_conv1)\n",
    "                weights['bc%d' % (i+1)] = safe_get('bc%d' % (i+1), [num_filters[i]], dtype=tf.float32, trainable=train_pretrain_conv1)\n",
    "                pretrain_weight = h5py.File(pretrain_weight_path, 'r')\n",
    "                conv_weight = pretrain_weight['block1_conv%d' % (i+1)]['block1_conv%d_W_1:0' % (i+1)][...]\n",
    "                conv_bias = pretrain_weight['block1_conv%d' % (i+1)]['block1_conv%d_b_1:0' % (i+1)][...]\n",
    "                weights['wc%d' % (i+1)].assign(conv_weight)\n",
    "                weights['bc%d' % (i+1)].assign(conv_bias)\n",
    "                fan_in = conv_weight.shape[-1]\n",
    "\n",
    "        # fc weights\n",
    "        in_shape = self.conv_out_size\n",
    "        if not FLAGS.no_state:\n",
    "            in_shape += len(self.state_idx)\n",
    "        if FLAGS.fc_bt:\n",
    "            in_shape += FLAGS.bt_dim\n",
    "        if FLAGS.fc_bt:\n",
    "            weights['context'] = safe_get('context', initializer=tf.zeros([FLAGS.bt_dim], dtype=tf.float32))\n",
    "        fc_weights = self.construct_fc_weights(in_shape, dim_output, network_config=network_config)\n",
    "        self.conv_out_size_final = in_shape\n",
    "        weights.update(fc_weights)\n",
    "        return weights\n",
    "\n",
    "    def construct_fc_weights(self, dim_input=27, dim_output=7, network_config=None):\n",
    "        n_layers = network_config.get('n_layers', 4)\n",
    "        dim_hidden = network_config.get('layer_size', [100]*(n_layers-1))\n",
    "        if type(dim_hidden) is not list:\n",
    "            dim_hidden = (n_layers - 1)*[dim_hidden]\n",
    "        dim_hidden.append(dim_output)\n",
    "        weights = {}\n",
    "        in_shape = dim_input\n",
    "        for i in xrange(n_layers):\n",
    "            if FLAGS.two_arms and i == 0:\n",
    "                if self.norm_type == 'selu':\n",
    "                    weights['w_%d_img' % i] = init_fc_weights_snn([in_shape-len(self.state_idx), dim_hidden[i]], name='w_%d_img' % i)\n",
    "                    weights['w_%d_state' % i] = init_fc_weights_snn([len(self.state_idx), dim_hidden[i]], name='w_%d_state' % i)\n",
    "                else:\n",
    "                    weights['w_%d_img' % i] = init_weights([in_shape-len(self.state_idx), dim_hidden[i]], name='w_%d_img' % i)\n",
    "                    weights['w_%d_state' % i] = init_weights([len(self.state_idx), dim_hidden[i]], name='w_%d_state' % i)\n",
    "                    weights['b_%d_state_two_arms' % i] = init_bias([dim_hidden[i]], name='b_%d_state_two_arms' % i)\n",
    "                weights['b_%d_img' % i] = init_bias([dim_hidden[i]], name='b_%d_img' % i)\n",
    "                weights['b_%d_state' % i] = init_bias([dim_hidden[i]], name='b_%d_state' % i)\n",
    "                in_shape = dim_hidden[i]\n",
    "                continue\n",
    "            if i > 0 and FLAGS.all_fc_bt:\n",
    "                in_shape += FLAGS.bt_dim\n",
    "                weights['context_%d' % i] = init_bias([FLAGS.bt_dim], name='context_%d' % i)\n",
    "            if self.norm_type == 'selu':\n",
    "                weights['w_%d' % i] = init_fc_weights_snn([in_shape, dim_hidden[i]], name='w_%d' % i)\n",
    "            else:\n",
    "                weights['w_%d' % i] = init_weights([in_shape, dim_hidden[i]], name='w_%d' % i)\n",
    "            weights['b_%d' % i] = init_bias([dim_hidden[i]], name='b_%d' % i)\n",
    "            if (i == n_layers - 1 or (i == 0 and FLAGS.zero_state and not FLAGS.two_arms)) and FLAGS.two_head:\n",
    "                weights['w_%d_two_heads' % i] = init_weights([in_shape, dim_hidden[i]], name='w_%d_two_heads' % i)\n",
    "                weights['b_%d_two_heads' % i] = init_bias([dim_hidden[i]], name='b_%d_two_heads' % i)\n",
    "            in_shape = dim_hidden[i]\n",
    "        return weights\n",
    "\n",
    "    def forward(self, image_input, state_input, weights, meta_testing=False, is_training=True, testing=False, network_config=None):\n",
    "        \"\"\" Perform the forward pass. \"\"\"\n",
    "        if FLAGS.fc_bt:\n",
    "            im_height = network_config['image_height']\n",
    "            im_width = network_config['image_width']\n",
    "            num_channels = network_config['image_channels']\n",
    "            flatten_image = tf.reshape(image_input, [-1, im_height*im_width*num_channels])\n",
    "            context = tf.transpose(tf.gather(tf.transpose(tf.zeros_like(flatten_image)), range(FLAGS.bt_dim)))\n",
    "            context += weights['context']\n",
    "        norm_type = self.norm_type\n",
    "        decay = network_config.get('decay', 0.9)\n",
    "        strides = network_config.get('strides', [[1, 2, 2, 1], [1, 2, 2, 1], [1, 2, 2, 1]])\n",
    "        downsample_factor = strides[0][1]\n",
    "        n_strides = len(strides)\n",
    "        n_conv_layers = len(strides)\n",
    "        use_dropout = FLAGS.dropout\n",
    "        prob = FLAGS.keep_prob\n",
    "        is_dilated = network_config.get('is_dilated', False)\n",
    "        im_height = network_config['image_height']\n",
    "        im_width = network_config['image_width']\n",
    "        num_channels = network_config['image_channels']\n",
    "        conv_layer = image_input\n",
    "        if FLAGS.conv_bt:\n",
    "            img_context = tf.zeros_like(conv_layer)\n",
    "            img_context += weights['img_context']\n",
    "            conv_layer = tf.concat(axis=3, values=[conv_layer, img_context])\n",
    "        for i in xrange(n_conv_layers):\n",
    "            if not use_dropout:\n",
    "                conv_layer = norm(conv2d(img=conv_layer, w=weights['wc%d' % (i+1)], b=weights['bc%d' % (i+1)], strides=strides[i], is_dilated=is_dilated), \\\n",
    "                                norm_type=norm_type, decay=decay, id=i, is_training=is_training, activation_fn=self.activation_fn)\n",
    "            else:\n",
    "                conv_layer = dropout(norm(conv2d(img=conv_layer, w=weights['wc%d' % (i+1)], b=weights['bc%d' % (i+1)], strides=strides[i], is_dilated=is_dilated), \\\n",
    "                                norm_type=norm_type, decay=decay, id=i, is_training=is_training, activation_fn=self.activation_fn), keep_prob=prob, is_training=is_training, name='dropout_%d' % (i+1))\n",
    "        if FLAGS.fp:\n",
    "            _, num_rows, num_cols, num_fp = conv_layer.get_shape()\n",
    "            if is_dilated:\n",
    "                num_rows = int(np.ceil(im_width/(downsample_factor**n_strides)))\n",
    "                num_cols = int(np.ceil(im_height/(downsample_factor**n_strides)))\n",
    "            num_rows, num_cols, num_fp = [int(x) for x in [num_rows, num_cols, num_fp]]\n",
    "            x_map = np.empty([num_rows, num_cols], np.float32)\n",
    "            y_map = np.empty([num_rows, num_cols], np.float32)\n",
    "\n",
    "            for i in range(num_rows):\n",
    "                for j in range(num_cols):\n",
    "                    x_map[i, j] = (i - num_rows / 2.0) / num_rows\n",
    "                    y_map[i, j] = (j - num_cols / 2.0) / num_cols\n",
    "\n",
    "            x_map = tf.convert_to_tensor(x_map)\n",
    "            y_map = tf.convert_to_tensor(y_map)\n",
    "\n",
    "            x_map = tf.reshape(x_map, [num_rows * num_cols])\n",
    "            y_map = tf.reshape(y_map, [num_rows * num_cols])\n",
    "\n",
    "            # rearrange features to be [batch_size, num_fp, num_rows, num_cols]\n",
    "            features = tf.reshape(tf.transpose(conv_layer, [0,3,1,2]),\n",
    "                                  [-1, num_rows*num_cols])\n",
    "            softmax = tf.nn.softmax(features)\n",
    "\n",
    "            fp_x = tf.reduce_sum(tf.multiply(x_map, softmax), [1], keep_dims=True)\n",
    "            fp_y = tf.reduce_sum(tf.multiply(y_map, softmax), [1], keep_dims=True)\n",
    "\n",
    "            conv_out_flat = tf.reshape(tf.concat(axis=1, values=[fp_x, fp_y]), [-1, num_fp*2])\n",
    "        else:\n",
    "            conv_out_flat = tf.reshape(conv_layer, [-1, self.conv_out_size])\n",
    "        fc_input = tf.add(conv_out_flat, 0)\n",
    "        if FLAGS.fc_bt:\n",
    "            fc_input = tf.concat(axis=1, values=[fc_input, context])\n",
    "        return self.fc_forward(fc_input, weights, state_input=state_input, meta_testing=meta_testing, is_training=is_training, testing=testing, network_config=network_config)\n",
    "\n",
    "    def fc_forward(self, fc_input, weights, state_input=None, meta_testing=False, is_training=True, testing=False, network_config=None):\n",
    "        n_layers = network_config.get('n_layers', 4)\n",
    "        use_dropout = FLAGS.dropout\n",
    "        prob = FLAGS.keep_prob\n",
    "        fc_output = tf.add(fc_input, 0)\n",
    "        use_selu = self.norm_type == 'selu'\n",
    "        norm_type = self.norm_type\n",
    "        if state_input is not None and not FLAGS.two_arms:\n",
    "            fc_output = tf.concat(axis=1, values=[fc_output, state_input])\n",
    "        for i in xrange(n_layers):\n",
    "            if i > 0 and FLAGS.all_fc_bt:\n",
    "                context = tf.transpose(tf.gather(tf.transpose(tf.zeros_like(fc_output)), range(FLAGS.bt_dim)))\n",
    "                context += weights['context_%d' % i]\n",
    "                fc_output = tf.concat(axis=1, values=[fc_output, context])\n",
    "            if (i == n_layers - 1 or (i == 0 and FLAGS.zero_state and not FLAGS.two_arms)) and FLAGS.two_head and not meta_testing:\n",
    "                fc_output = tf.matmul(fc_output, weights['w_%d_two_heads' % i]) + weights['b_%d_two_heads' % i]\n",
    "            elif i == 0 and FLAGS.two_arms:\n",
    "                assert state_input is not None\n",
    "                if FLAGS.two_arms:\n",
    "                    state_part = weights['b_%d_state_two_arms' % i]\n",
    "                else:\n",
    "                    state_part = tf.matmul(state_input, weights['w_%d_state' % i]) + weights['b_%d_state' % i]\n",
    "                if not meta_testing:\n",
    "                    fc_output = tf.matmul(fc_output, weights['w_%d_img' % i]) + weights['b_%d_img' % i] + state_part\n",
    "                else:\n",
    "                    fc_output = tf.matmul(fc_output, weights['w_%d_img' % i]) + weights['b_%d_img' % i] + \\\n",
    "                                tf.matmul(state_input, weights['w_%d_state' % i]) + weights['b_%d_state' % i]\n",
    "            else:\n",
    "                fc_output = tf.matmul(fc_output, weights['w_%d' % i]) + weights['b_%d' % i]\n",
    "            if i != n_layers - 1:\n",
    "                if use_selu:\n",
    "                    fc_output = selu(fc_output)\n",
    "                else:\n",
    "                    fc_output = self.activation_fn(fc_output)\n",
    "                # only use dropout for post-update\n",
    "                if use_dropout:\n",
    "                    fc_output = dropout(fc_output, keep_prob=prob, is_training=is_training, name='dropout_fc_%d' % i, selu=use_selu)\n",
    "        return fc_output\n",
    "\n",
    "    def construct_model(self, input_tensors=None, prefix='Training_', dim_input=27, dim_output=7, network_config=None):\n",
    "        \"\"\"\n",
    "        Construct the meta-learning graph.\n",
    "        Args:\n",
    "            input_tensors: tensors of input videos, if available\n",
    "            prefix: indicate whether we are building training, validation or testing graph.\n",
    "            dim_input: Dimensionality of input.\n",
    "            dim_output: Dimensionality of the output.\n",
    "            network_config: dictionary of network structure parameters\n",
    "        Returns:\n",
    "            a tuple of output tensors.\n",
    "        \"\"\"\n",
    "        if input_tensors is None:\n",
    "            self.obsa = obsa = tf.placeholder(tf.float32, name='obsa') # meta_batch_size x update_batch_size x dim_input\n",
    "            self.obsb = obsb = tf.placeholder(tf.float32, name='obsb')\n",
    "        else:\n",
    "            self.obsa = obsa = input_tensors['inputa'] # meta_batch_size x update_batch_size x dim_input\n",
    "            self.obsb = obsb = input_tensors['inputb']\n",
    "\n",
    "        if not hasattr(self, 'statea'):\n",
    "            self.statea = statea = tf.placeholder(tf.float32, name='statea')\n",
    "            self.stateb = stateb = tf.placeholder(tf.float32, name='stateb')\n",
    "            self.actiona = actiona = tf.placeholder(tf.float32, name='actiona')\n",
    "            self.actionb = actionb = tf.placeholder(tf.float32, name='actionb')\n",
    "        else:\n",
    "            statea = self.statea\n",
    "            stateb = self.stateb\n",
    "            actiona = self.actiona\n",
    "            actionb = self.actionb\n",
    "\n",
    "        inputa = tf.concat(axis=2, values=[statea, obsa])\n",
    "        inputb = tf.concat(axis=2, values=[stateb, obsb])\n",
    "\n",
    "        with tf.variable_scope('model', reuse=None) as training_scope:\n",
    "            # Construct layers weight & bias\n",
    "            if 'weights' not in dir(self):\n",
    "                self.weights = weights = self.construct_weights(dim_input, dim_output, network_config=network_config)\n",
    "                self.sorted_weight_keys = natsorted(self.weights.keys())\n",
    "            else:\n",
    "                training_scope.reuse_variables()\n",
    "                weights = self.weights\n",
    "\n",
    "            self.step_size = FLAGS.train_update_lr\n",
    "            loss_multiplier = FLAGS.loss_multiplier\n",
    "            act_loss_eps = FLAGS.act_loss_eps\n",
    "\n",
    "            num_updates = self.num_updates\n",
    "            lossesa, outputsa = [], []\n",
    "            lossesb = [[] for _ in xrange(num_updates)]\n",
    "            outputsb = [[] for _ in xrange(num_updates)]\n",
    "\n",
    "            def batch_metalearn(inp):\n",
    "                inputa, inputb, actiona, actionb = inp\n",
    "                inputa = tf.reshape(inputa, [-1, dim_input])\n",
    "                inputb = tf.reshape(inputb, [-1, dim_input])\n",
    "                actiona = tf.reshape(actiona, [-1, dim_output])\n",
    "                actionb = tf.reshape(actionb, [-1, dim_output])\n",
    "                gradients_summ = []\n",
    "                testing = 'Testing' in prefix\n",
    "\n",
    "                if FLAGS.no_action:\n",
    "                    actiona = tf.zeros_like(actiona)\n",
    "\n",
    "                local_outputbs, local_lossesb = [], [], []\n",
    "                # Assume fixed data for each update\n",
    "                actionas = [actiona]*num_updates\n",
    "\n",
    "                # Convert to image dims\n",
    "                inputa, _, state_inputa = self.construct_image_input(inputa, self.state_idx, self.img_idx, network_config=network_config)\n",
    "                inputb, flat_img_inputb, state_inputb = self.construct_image_input(inputb, self.state_idx, self.img_idx, network_config=network_config)\n",
    "                inputas = [inputa]*num_updates\n",
    "                inputbs = [inputb]*num_updates\n",
    "                if FLAGS.zero_state:\n",
    "                    state_inputa = tf.zeros_like(state_inputa)\n",
    "                state_inputas = [state_inputa]*num_updates\n",
    "                if FLAGS.no_state:\n",
    "                    state_inputa = None\n",
    "                # Pre-update\n",
    "                if 'Training' in prefix:\n",
    "                    local_outputa = self.forward(inputa, state_inputa, weights, network_config=network_config)\n",
    "                else:\n",
    "                    local_outputa = self.forward(inputa, state_inputa, weights, is_training=False, network_config=network_config)\n",
    "                local_lossa = act_loss_eps * euclidean_loss_layer(local_outputa, actiona, multiplier=loss_multiplier, use_l1=FLAGS.use_l1_l2_loss)\n",
    "\n",
    "\n",
    "                # Compute fast gradients\n",
    "                grads = tf.gradients(local_lossa, weights.values())\n",
    "                gradients = dict(zip(weights.keys(), grads))\n",
    "                # make fast gradient zero for weights with gradient None\n",
    "                for key in gradients.keys():\n",
    "                    if gradients[key] is None:\n",
    "                        gradients[key] = tf.zeros_like(weights[key])\n",
    "                if FLAGS.stop_grad:\n",
    "                    gradients = {key:tf.stop_gradient(gradients[key]) for key in gradients.keys()}\n",
    "                if FLAGS.clip:\n",
    "                    clip_min = FLAGS.clip_min\n",
    "                    clip_max = FLAGS.clip_max\n",
    "                    for key in gradients.keys():\n",
    "                        gradients[key] = tf.clip_by_value(gradients[key], clip_min, clip_max)\n",
    "                if FLAGS.pretrain_weight_path != 'N/A':\n",
    "                    gradients['wc1'] = tf.zeros_like(gradients['wc1'])\n",
    "                    gradients['bc1'] = tf.zeros_like(gradients['bc1'])\n",
    "                gradients_summ.append([gradients[key] for key in self.sorted_weight_keys])\n",
    "                fast_weights = dict(zip(weights.keys(), [weights[key] - self.step_size*gradients[key] for key in weights.keys()]))\n",
    "\n",
    "                # Post-update\n",
    "                if FLAGS.no_state:\n",
    "                    state_inputb = None\n",
    "                if 'Training' in prefix:\n",
    "                    outputb = self.forward(inputb, state_inputb, fast_weights, meta_testing=True, network_config=network_config)\n",
    "                else:\n",
    "                    outputb = self.forward(inputb, state_inputb, fast_weights, meta_testing=True, is_training=False, testing=testing, network_config=network_config)\n",
    "                local_outputbs.append(outputb)\n",
    "                local_lossb = act_loss_eps * euclidean_loss_layer(outputb, actionb, multiplier=loss_multiplier, use_l1=FLAGS.use_l1_l2_loss)\n",
    "                local_lossesb.append(local_lossb)\n",
    "\n",
    "                for j in range(num_updates - 1):\n",
    "                    # Pre-update\n",
    "                    state_inputa_new = state_inputas[j+1]\n",
    "                    if FLAGS.no_state:\n",
    "                        state_inputa_new = None\n",
    "                    if 'Training' in prefix:\n",
    "                        outputa = self.forward(inputas[j+1], state_inputa_new, fast_weights, network_config=network_config)\n",
    "                    else:\n",
    "                        outputa = self.forward(inputas[j+1], state_inputa_new, fast_weights, is_training=False, testing=testing, network_config=network_config)\n",
    "                    loss = act_loss_eps * euclidean_loss_layer(outputa, actionas[j+1], multiplier=loss_multiplier, use_l1=FLAGS.use_l1_l2_loss)\n",
    "\n",
    "                    # Compute fast gradients\n",
    "                    grads = tf.gradients(loss, fast_weights.values())\n",
    "                    gradients = dict(zip(fast_weights.keys(), grads))\n",
    "                    # make fast gradient zero for weights with gradient None\n",
    "                    for key in gradients.keys():\n",
    "                        if gradients[key] is None:\n",
    "                            gradients[key] = tf.zeros_like(fast_weights[key])\n",
    "                    if FLAGS.stop_grad:\n",
    "                        gradients = {key:tf.stop_gradient(gradients[key]) for key in gradients.keys()}\n",
    "                    if FLAGS.clip:\n",
    "                        clip_min = FLAGS.clip_min\n",
    "                        clip_max = FLAGS.clip_max\n",
    "                        for key in gradients.keys():\n",
    "                            gradients[key] = tf.clip_by_value(gradients[key], clip_min, clip_max)\n",
    "                    if FLAGS.pretrain_weight_path != 'N/A':\n",
    "                        gradients['wc1'] = tf.zeros_like(gradients['wc1'])\n",
    "                        gradients['bc1'] = tf.zeros_like(gradients['bc1'])\n",
    "                    gradients_summ.append([gradients[key] for key in self.sorted_weight_keys])\n",
    "                    fast_weights = dict(zip(fast_weights.keys(), [fast_weights[key] - self.step_size*gradients[key] for key in fast_weights.keys()]))\n",
    "\n",
    "                    # Post-update\n",
    "                    if FLAGS.no_state:\n",
    "                        state_inputb = None\n",
    "                    if 'Training' in prefix:\n",
    "                        output = self.forward(inputbs[j+1], state_inputb, fast_weights, meta_testing=True, network_config=network_config)\n",
    "                    else:\n",
    "                        output = self.forward(inputbs[j+1], state_inputb, fast_weights, meta_testing=True, is_training=False, testing=testing, network_config=network_config)\n",
    "                    local_outputbs.append(output)\n",
    "                    lossb = act_loss_eps * euclidean_loss_layer(output, actionb, multiplier=loss_multiplier, use_l1=FLAGS.use_l1_l2_loss)\n",
    "                    local_lossesb.append(lossb)\n",
    "                local_fn_output = [local_outputa, local_outputbs, local_outputbs[-1], local_lossa, local_lossesb, flat_img_inputb, gradients_summ]\n",
    "                return local_fn_output\n",
    "\n",
    "        out_dtype = [tf.float32, [tf.float32]*num_updates, tf.float32, tf.float32, [tf.float32]*num_updates, [tf.float32]*num_updates, tf.float32, [[tf.float32]*len(self.weights.keys())]*num_updates]\n",
    "        result = tf.map_fn(batch_metalearn, elems=(inputa, inputb, actiona, actionb), dtype=out_dtype)\n",
    "        print 'Done with map.'\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
