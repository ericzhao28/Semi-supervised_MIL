{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, clone_model, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, TimeDistributed, Conv2D, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Concatenate, CuDNNLSTM, Cropping1D\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "tf.reset_default_graph()\n",
    "TD = TimeDistributed\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "T_in = 16\n",
    "T_total = 100\n",
    "IMG_H = 125\n",
    "IMG_W = 125\n",
    "IMG_CH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit initial conv:  (?, 16, 3, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "def build_autoencoder():\n",
    "  inputs = Input(shape=(T_in, IMG_H, IMG_W, IMG_CH))\n",
    "  # Apply convolutions on the initial image input with increasing channel size.\n",
    "  conv_x = TD(Conv2D(32, kernel_size=(3, 3), strides=(2, 2), activation='relu'))(inputs)\n",
    "  conv_x = TD(MaxPooling2D(pool_size=(2, 2)))(conv_x)\n",
    "  conv_x = TD(Conv2D(64, kernel_size=(3, 3), strides=(2, 2), activation='relu'))(conv_x)\n",
    "  conv_x = TD(MaxPooling2D(pool_size=(2, 2)))(conv_x)\n",
    "  conv_x = TD(Conv2D(128, kernel_size=(3, 3), strides=(2, 2), activation='relu'))(conv_x)\n",
    "  print(\"Exit initial conv: \", conv_x.shape)\n",
    "\n",
    "  # We pass the flattened convolution output into a CuDNN-optimized LSTM.\n",
    "  # Outputs are disregarded for training but form the \"encoded\" representation.\n",
    "  enc_x = Reshape((T_in, -1))(conv_x)\n",
    "  encoded = Concatenate()(CuDNNLSTM(1024, return_state=True, return_sequences=False)(enc_x))\n",
    "  return Model(inputs=inputs, outputs=encoded)\n",
    "\n",
    "autoencoder = build_autoencoder()\n",
    "autoencoder.load_weights(\"/home/ubuntu/semisupervised_mil/autoencoder/model_weights_6.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_worse_model():\n",
    "  inputs = Input(shape=(T_in, IMG_H, IMG_W, IMG_CH))\n",
    "  model = TD(Flatten())(inputs)\n",
    "  model = Cropping1D(cropping=(T_in - 1, 0))(model)\n",
    "  model = Reshape((IMG_H, IMG_W, IMG_CH))(model)\n",
    "  model = Convolution2D(32, (3, 3), padding='same', activation=\"relu\")(model)\n",
    "  model = MaxPooling2D(pool_size=(3, 3))(model)\n",
    "  model = Convolution2D(32, (3, 3), padding='same', activation=\"relu\")(model)\n",
    "  model = MaxPooling2D(pool_size=(3, 3))(model)\n",
    "  model = Dropout(0.25)(model)\n",
    "  model = Flatten()(model)\n",
    "  model = Dense(512, activation=\"relu\")(model)\n",
    "  model = Dropout(0.5)(model)\n",
    "  preds = Dense(7, activation=\"tanh\")(model)\n",
    "  \n",
    "  keras_model = Model(inputs=inputs, outputs=preds)\n",
    "  \n",
    "  return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_better_model():\n",
    "  inputs = Input(shape=(T_in, IMG_H, IMG_W, IMG_CH))\n",
    "  model = autoencoder(inputs)\n",
    "  model = Dense(512, activation=\"relu\")(model)\n",
    "  model = Dropout(0.5)(model)\n",
    "  preds = Dense(7, activation=\"tanh\")(model)\n",
    "  keras_model = Model(inputs=inputs, outputs=preds)\n",
    "  \n",
    "  return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMEMBER TO UPDATE\n",
    "build_model = build_better_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train_input = tf.placeholder(tf.float32, shape=(batch_size, T_in, IMG_H, IMG_W, IMG_CH))\n",
    "train_label = tf.placeholder(tf.float32, shape=(batch_size, 7))\n",
    "# Build initial model\n",
    "before_model = build_model()\n",
    "# Calulate initial loss\n",
    "before_pred = before_model(train_input)\n",
    "# Calculate loss and gradient for the task\n",
    "before_loss = tf.reduce_mean(mean_squared_error(train_label, before_pred))\n",
    "before_gradients = tf.gradients(before_loss, before_model.trainable_weights)\n",
    "# Calculate ethereal weights for task-specific network\n",
    "ethereal = {}\n",
    "for weight, gradient in zip(before_model.trainable_weights, before_gradients):\n",
    "  ethereal[weight] = weight - learning_rate * gradient\n",
    "# Load test data\n",
    "specialized_copy_ops = []\n",
    "test_input = tf.placeholder(tf.float32, shape=(batch_size, T_in, IMG_H, IMG_W, IMG_CH))\n",
    "test_label = tf.placeholder(tf.float32, shape=(batch_size, 7))\n",
    "# Build new ethereal model\n",
    "after_model = build_model()\n",
    "for before_weight, after_weight in zip(before_model.trainable_weights,\n",
    "                                       after_model.trainable_weights):\n",
    "  specialized_copy_ops.append(tf.assign(after_weight, ethereal[before_weight]))\n",
    "# Calculate the final gradients!\n",
    "after_pred = after_model(test_input)\n",
    "after_loss = tf.reduce_mean(mean_squared_error(test_label, after_pred))\n",
    "after_grads = tf.gradients(after_loss, after_model.trainable_weights)\n",
    "\n",
    "# Update our meta weights!\n",
    "meta_ops = []\n",
    "for before_weight, grad in zip(before_model.trainable_weights, after_grads):\n",
    "  meta_ops.append(tf.assign(before_weight, before_weight - learning_rate * grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x, train_y, test_x, test_y):\n",
    "  sess.run(specialized_copy_ops, feed_dict={train_input: train_x,\n",
    "                                            train_label: train_y})\n",
    "  sess.run(meta_ops, feed_dict={test_input: test_x,\n",
    "                                test_label: test_y})\n",
    "  \n",
    "def test(train_x, train_y, test_x, test_y):\n",
    "  sess.run(specialized_copy_ops, feed_dict={train_input: train_x,\n",
    "                                            train_label: train_y})\n",
    "  return sess.run(after_loss, feed_dict={test_input: test_x,\n",
    "                                         test_label: test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e6194d2c7a5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for i in range(epochs):\n",
    "  for train_x, train_y, test_x, test_y in return_data(batch_size):\n",
    "    for i in range(15, T_total):\n",
    "      train(train_x[:,i-15:i+1], train_y[:,i], test_x[:,i-15:i+1], test_y[:,i])\n",
    "      print(test(train_x[:,i-15:i+1], train_y[:,i], test_x[:,i-15:i+1], test_y[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "    \n",
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, random, os\n",
    "import contextlib\n",
    "@contextlib.contextmanager\n",
    "def open_zip(filename, mode='r'):\n",
    "    \"\"\"\n",
    "    Open a file; if filename ends with .gz, opens as a gzip file\n",
    "    \"\"\"\n",
    "    if filename.endswith('.gz'):\n",
    "        openfn = gzip.open\n",
    "    else:\n",
    "        openfn = open\n",
    "    yield openfn(filename, mode)\n",
    "class DataLogger(object):\n",
    "    \"\"\"\n",
    "    This class pickles data into files and unpickles data from files.\n",
    "    TODO: Handle logging text to terminal, GUI text, and/or log file at\n",
    "        DEBUG, INFO, WARN, ERROR, FATAL levels.\n",
    "    TODO: Handle logging data to terminal, GUI text/plots, and/or data\n",
    "          files.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def pickle(self, filename, data):\n",
    "        \"\"\" Pickle data into file specified by filename. \"\"\"\n",
    "        with open_zip(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def unpickle(self, filename):\n",
    "        \"\"\" Unpickle data from file specified by filename. \"\"\"\n",
    "        try:\n",
    "            with open_zip(filename, 'rb') as f:\n",
    "                result = pickle.load(f, encoding='latin1')\n",
    "            return result\n",
    "        except IOError:\n",
    "            LOGGER.debug('Unpickle error. Cannot find file: %s', filename)\n",
    "            return None\n",
    "\n",
    "def extract_demo_dict(demo_file):\n",
    "    if type(demo_file) is not list:\n",
    "        demos = DataLogger().unpickle(demo_file)\n",
    "    else:\n",
    "        demos = {}\n",
    "        for i in range(0, len(demo_file)):\n",
    "            demos[i] = DataLogger().unpickle(demo_file[i])\n",
    "    return demos\n",
    "\n",
    "from PIL import Image, ImageSequence\n",
    "from natsort import natsorted\n",
    "import glob\n",
    "def gif_to_np(path):\n",
    "  def __frame_to_np(frame):\n",
    "    return np.array(frame.copy().convert(\"RGB\").getdata(),\n",
    "                    dtype=np.uint8).reshape(frame.size[1],\n",
    "                                            frame.size[0], 3)\n",
    "\n",
    "  im = Image.open(path)\n",
    "  data = np.array(list(map(__frame_to_np, ImageSequence.Iterator(im))))\n",
    "  return data\n",
    "\n",
    "\n",
    "def load_path(paths_queue):\n",
    "  for p in glob.glob(DATA_PATH + \"/.gif\"):\n",
    "    paths_queue.put(p)\n",
    "  return\n",
    "\n",
    "\n",
    "def return_data(batch_size=5):\n",
    "  \"\"\" \n",
    "    Returns one demoX entry, demoU entry, and corresponding gif entry\n",
    "  \"\"\"\n",
    "  demo_file = '/home/ubuntu/data/sim_push/'\n",
    "  demo_gif_dir = '/home/ubuntu/data/sim_push/'\n",
    "  gif_prefix = 'object'\n",
    "\n",
    "  demo_files = natsorted(glob.glob(demo_file + '/*pkl'))\n",
    "  result1 = {}\n",
    "  result2 = {}\n",
    "  for num in range(0, len(demo_files), batch_size):\n",
    "    batch_result = ()\n",
    "    for b in range(num, batch_size):\n",
    "\n",
    "      # Extracting data from the applicable demo\n",
    "      demos = extract_demo_dict([demo_files[b]])\n",
    "      key = list(demos.keys())[0]\n",
    "\n",
    "      # Numbers for the two random samples being picked\n",
    "      rand_entry_1, rand_entry_2 = random.sample(range(0, len(demos[key]['demoX'])), 2)\n",
    "\n",
    "      gif_folder = os.path.join(demo_gif_dir, gif_prefix + '_%d' % b)\n",
    "      image_paths = natsorted(os.listdir(gif_folder))\n",
    "\n",
    "      #result1['demoX'] = demos[key]['demoX'][rand_entry_1]\n",
    "      result1['demoU'] = demos[key]['demoU'][rand_entry_1]\n",
    "      result1['gif'] = gif_to_np(gif_folder + '/' +  image_paths[rand_entry_1])\n",
    "\n",
    "      #result2['demoX'] = demos[key]['demoX'][rand_entry_2]\n",
    "      result2['demoU'] = demos[key]['demoU'][rand_entry_2]\n",
    "      result2['gif'] = gif_to_np(gif_folder + '/' +  image_paths[rand_entry_2])\n",
    "\n",
    "      batch_result += result1['demoU'], result1['gif'], result2['demoU'], result2['gif']\n",
    "    yield batch_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
